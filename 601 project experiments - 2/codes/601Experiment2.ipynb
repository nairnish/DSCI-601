{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of All labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Yash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define paths for train,dev and test-gold datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'C:/Users/Yash/Downloads/DSLCCv4.0_1/DSL-TRAIN.txt'\n",
    "dev_path = 'C:/Users/Yash/Downloads/DSLCCv4.0_1/DSL-DEV.txt'\n",
    "test_path = 'C:/Users/Yash/Downloads/DSLCCv4.0_1/DSL-TEST-GOLD.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pre-process data \n",
    "\n",
    "@param: path : file path\n",
    "@return: df : DataFrame with the DSLCC - train,test (gold) or dev\n",
    "\n",
    "'''\n",
    "def preprocess(path):\n",
    "    data = []\n",
    "    #Reading contents from file \n",
    "    file_contents = open(path,\"r\",encoding=\"utf-8\")\n",
    "    #Appending read data to the file\n",
    "    data.append(file_contents.read())\n",
    "    text = []\n",
    "    language = []\n",
    "    #splitting each instance by \\n\n",
    "    temp = data[0].split(\"\\n\")\n",
    "    for i in range(len(temp)):\n",
    "        #putting each instance's text into one column\n",
    "        text.append(temp[i].split(\"\\t\")[0])\n",
    "        #putting language variety into second column\n",
    "        language.append(temp[i].split(\"\\t\")[1])\n",
    "    #making the DataFrame    \n",
    "    df = pd.DataFrame(data={'text':text,'language':language})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list_persian = [\n",
    "و\n",
    "در\n",
    "به\n",
    "از\n",
    "كه\n",
    "مي\n",
    "اين\n",
    "است\n",
    "را\n",
    "با\n",
    "هاي\n",
    "براي\n",
    "آن\n",
    "يك\n",
    "شود\n",
    "شده\n",
    "خود\n",
    "ها\n",
    "كرد\n",
    "شد\n",
    "اي\n",
    "تا\n",
    "كند\n",
    "بر\n",
    "بود\n",
    "گفت\n",
    "نيز\n",
    "وي\n",
    "هم\n",
    "كنند\n",
    "دارد\n",
    "ما\n",
    "كرده\n",
    "يا\n",
    "اما\n",
    "بايد\n",
    "دو\n",
    "اند\n",
    "هر\n",
    "خواهد\n",
    "او\n",
    "مورد\n",
    "آنها\n",
    "باشد\n",
    "ديگر\n",
    "مردم\n",
    "نمي\n",
    "بين\n",
    "پيش\n",
    "پس\n",
    "اگر\n",
    "همه\n",
    "صورت\n",
    "يكي\n",
    "هستند\n",
    "بي\n",
    "من\n",
    "دهد\n",
    "هزار\n",
    "نيست\n",
    "استفاده\n",
    "داد\n",
    "داشته\n",
    "راه\n",
    "داشت\n",
    "چه\n",
    "همچنين\n",
    "كردند\n",
    "داده\n",
    "بوده\n",
    "دارند\n",
    "همين\n",
    "ميليون\n",
    "سوي\n",
    "شوند\n",
    "بيشتر\n",
    "بسيار\n",
    "روي\n",
    "گرفته\n",
    "هايي\n",
    "تواند\n",
    "اول\n",
    "نام\n",
    "هيچ\n",
    "چند\n",
    "جديد\n",
    "بيش\n",
    "شدن\n",
    "كردن\n",
    "كنيم\n",
    "نشان\n",
    "حتي\n",
    "اينكه\n",
    "ولی\n",
    "توسط\n",
    "چنين\n",
    "برخي\n",
    "نه\n",
    "ديروز\n",
    "دوم\n",
    "درباره\n",
    "بعد\n",
    "مختلف\n",
    "گيرد\n",
    "شما\n",
    "گفته\n",
    "آنان\n",
    "بار\n",
    "طور\n",
    "گرفت\n",
    "دهند\n",
    "گذاري\n",
    "بسياري\n",
    "طي\n",
    "بودند\n",
    "ميليارد\n",
    "بدون\n",
    "تمام\n",
    "كل\n",
    "تر\tبراساس\n",
    "شدند\n",
    "ترين\n",
    "امروز\n",
    "باشند\n",
    "ندارد\n",
    "چون\n",
    "قابل\n",
    "گويد\n",
    "ديگري\n",
    "همان\n",
    "خواهند\n",
    "قبل\n",
    "آمده\n",
    "اكنون\n",
    "تحت\n",
    "طريق\n",
    "گيري\n",
    "جاي\n",
    "هنوز\n",
    "چرا\n",
    "البته\n",
    "كنيد\n",
    "سازي\n",
    "سوم\n",
    "كنم\n",
    "بلكه\n",
    "زير\n",
    "توانند\n",
    "ضمن\n",
    "فقط\n",
    "بودن\n",
    "حق\n",
    "آيد\n",
    "وقتي\n",
    "اش\n",
    "يابد\n",
    "نخستين\n",
    "مقابل\n",
    "خدمات\n",
    "امسال\n",
    "تاكنون\n",
    "مانند\n",
    "تازه\n",
    "آورد\n",
    "فكر\n",
    "آنچه\n",
    "نخست\n",
    "نشده\n",
    "شايد\n",
    "چهار\n",
    "جريان\n",
    "پنج\n",
    "ساخته\n",
    "زيرا\n",
    "نزديك\n",
    "برداري\n",
    "كسي\n",
    "ريزي\n",
    "رفت\n",
    "گردد\n",
    "مثل\n",
    "آمد\n",
    "ام\n",
    "بهترين\n",
    "دانست\n",
    "كمتر\n",
    "دادن\n",
    "تمامي\n",
    "جلوگيري\n",
    "بيشتري\n",
    "ايم\n",
    "ناشي\n",
    "چيزي\n",
    "آنكه\n",
    "بالا\n",
    "بنابراين\n",
    "ايشان\n",
    "بعضي\n",
    "دادند\n",
    "داشتند\n",
    "برخوردار\n",
    "نخواهد\n",
    "هنگام\n",
    "نبايد\n",
    "غير\n",
    "نبود\n",
    "ديده\n",
    "وگو\n",
    "داريم\n",
    "چگونه\n",
    "بندي\n",
    "خواست\n",
    "فوق\n",
    "ده\n",
    "نوعي\n",
    "هستيم\n",
    "ديگران\n",
    "همچنان\n",
    "سراسر\n",
    "ندارند\n",
    "گروهي\n",
    "سعي\n",
    "روزهاي\n",
    "آنجا\n",
    "يكديگر\n",
    "كردم\n",
    "بيست\n",
    "بروز\n",
    "سپس\n",
    "رفته\n",
    "آورده\n",
    "نمايد\n",
    "باشيم\n",
    "گويند\n",
    "زياد\n",
    "خويش\n",
    "همواره\n",
    "گذاشته\n",
    "شش\tنداشته\n",
    "شناسي\n",
    "خواهيم\n",
    "آباد\n",
    "داشتن\n",
    "نظير\n",
    "همچون\n",
    "باره\n",
    "نكرده\n",
    "شان\n",
    "سابق\n",
    "هفت\n",
    "دانند\n",
    "جايي\n",
    "بی\n",
    "جز\n",
    "زیرِ\n",
    "رویِ\n",
    "سریِ\n",
    "تویِ\n",
    "جلویِ\n",
    "پیشِ\n",
    "عقبِ\n",
    "بالایِ\n",
    "خارجِ\n",
    "وسطِ\n",
    "بیرونِ\n",
    "سویِ\n",
    "کنارِ\n",
    "پاعینِ\n",
    "نزدِ\n",
    "نزدیکِ\n",
    "دنبالِ\n",
    "حدودِ\n",
    "برابرِ\n",
    "طبقِ\n",
    "مانندِ\n",
    "ضدِّ\n",
    "هنگامِ\n",
    "برایِ\n",
    "مثلِ\n",
    "بارة\n",
    "اثرِ\n",
    "تولِ\n",
    "علّتِ\n",
    "سمتِ\n",
    "عنوانِ\n",
    "قصدِ\n",
    "روب\n",
    "جدا\n",
    "کی\n",
    "که\n",
    "چیست\n",
    "هست\n",
    "کجا\n",
    "کجاست\n",
    "کَی\n",
    "چطور\n",
    "کدام\n",
    "آیا\n",
    "مگر\n",
    "چندین\n",
    "یک\n",
    "چیزی\n",
    "دیگر\n",
    "کسی\n",
    "بعری\n",
    "هیچ\n",
    "چیز\n",
    "جا\n",
    "کس\n",
    "هرگز\n",
    "یا\n",
    "تنها\n",
    "بلکه\n",
    "خیاه\n",
    "بله\n",
    "بلی\n",
    "آره\n",
    "آری\n",
    "مرسی\n",
    "البتّه\n",
    "لطفاً\n",
    "ّه\n",
    "انکه\n",
    "وقتیکه\n",
    "همین\n",
    "پیش\n",
    "مدّتی\n",
    "هنگامی\n",
    "مان\n",
    "تان"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Stop-word removal for the train\n",
    "\n",
    "@param: df: training DataFrame\n",
    "\n",
    "@return: df_train: training DataFrame with stopwords removed\n",
    "\n",
    "'''\n",
    "def stopwords_removal(df):\n",
    "    #Stopwords for bosnian, indonesian, spanish, portuguese and french \n",
    "    stopwords_list_bosnian = stopwords.words(\"slovene\")\n",
    "    stopwords_list_indonesian = stopwords.words(\"indonesian\")\n",
    "    stopwords_list_spanish = stopwords.words(\"spanish\")\n",
    "    stopwords_list_portuguese = stopwords.words(\"portuguese\")\n",
    "    stopwords_list_french = stopwords.words(\"french\")\n",
    "    #combining stopwords into one list\n",
    "    stopwords_list_combine = stopwords_list_bosnian + stopwords_list_indonesian + stopwords_list_spanish + stopwords_list_portuguese + stopwords_list_french\n",
    "    newly_filtered_keyword1 = []\n",
    "    for i in range(len(df)):\n",
    "        #tokenizing the instances\n",
    "        tokens = nltk.word_tokenize(df['text'][i])\n",
    "        #Filtering the stopwords from the combined list\n",
    "        filtered_text = [t for t in tokens if t not in stopwords_list_combine]\n",
    "        #Appending new column with each instance\n",
    "        newly_filtered_keyword1.append(\" \".join(filtered_text))\n",
    "    df['newly_filtered_keyword'] = newly_filtered_keyword1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Tfidf Vectorizer \n",
    "\n",
    "@param: df_train : Training dataFrame\n",
    "@param: df_test_gold: Testing dataFrame withn gold standards\n",
    "\n",
    "@return: feature: training feature set\n",
    "@return: feature_test: testing feature set\n",
    "\n",
    "'''\n",
    "def vectorizer_tfidf(df_train,df_test_gold):\n",
    "    vectorizer = TfidfVectorizer() \n",
    "    vectorizer.fit(df_train['newly_filtered_keyword'])\n",
    "    feature = vectorizer.transform(df_train['newly_filtered_keyword'])\n",
    "    feature_test = vectorizer.transform(df_test_gold['text'])\n",
    "    return feature,feature_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Classification Report and Time to Run Support Vector Machine\n",
    "\n",
    "@param: df_train: Training dataFrame \n",
    "@param: df_test_gold: Testing dataFrame with gold standard\n",
    "\n",
    "@return: void \n",
    "\n",
    "'''\n",
    "def fit_predict_SVC(df_train,df_test):\n",
    "    clf_SVC = SVC()\n",
    "    start_time = time.time()\n",
    "    df_train = stopwords_removal(df_train)\n",
    "    df_test_gold = stopwords_removal(df_test)\n",
    "    feature,feature_test = vectorizer_tfidf(df_train,df_test_gold)\n",
    "    clf_SVC.fit(feature,df_train['language'])\n",
    "    predictions = clf_SVC.predict(feature_test)\n",
    "    print(classification_report(df_test_gold['language'],predictions))\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    print(\"Time taken to run Support Vector Machine is %f seconds\" %time_taken)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Classification Report and Time to Run K Nearest Neighbors\n",
    "\n",
    "@param: df_train: Training dataFrame \n",
    "@param: df_test_gold: Testing dataFrame with gold standard\n",
    "\n",
    "@return: void \n",
    "\n",
    "'''\n",
    "def fit_predict_KNN(df_train,df_test):\n",
    "    clf_KNN = KNeighborsClassifier(n_neighbors=10)\n",
    "    start_time = time.time()\n",
    "    df_train = stopwords_removal(df_train)\n",
    "    df_test_gold = stopwords_removal(df_test)\n",
    "    feature,feature_test = vectorizer_tfidf(df_train,df_test_gold)\n",
    "    clf_KNN.fit(feature,df_train['language'])\n",
    "    predictions = clf_KNN.predict(feature_test)\n",
    "    print(classification_report(df_test_gold['language'],predictions))\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time-start_time\n",
    "    print(\"Time taken to run K Neighbors Classifier is %f seconds\" %time_taken)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Classification Report and Time to Run Decision Tree Classifier\n",
    "\n",
    "@param: df_train: Training dataFrame \n",
    "@param: df_test_gold: Testing dataFrame with gold standard\n",
    "\n",
    "@return: void \n",
    "\n",
    "'''\n",
    "def fit_predict_DTC(df_train,df_test):\n",
    "    clf_dtc = DecisionTreeClassifier()\n",
    "    start_time = time.time()\n",
    "    df_train = stopwords_removal(df_train)\n",
    "    df_test_gold = stopwords_removal(df_test)\n",
    "    feature,feature_test = vectorizer_tfidf(df_train,df_test_gold)\n",
    "    clf_dtc.fit(feature,df_train['language'])\n",
    "    predictions = clf_dtc.predict(feature_test)\n",
    "    print(classification_report(df_test_gold['language'],predictions))\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    print(\"Time taken to run Decision Tree Classifier is %f seconds\" %time_taken)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Classification Report and Time to Run Random Forest Classifier\n",
    "\n",
    "@param: df_train: Training dataFrame \n",
    "@param: df_test_gold: Testing dataFrame with gold standard\n",
    "\n",
    "@return: void \n",
    "\n",
    "'''\n",
    "def fit_predict_RFC(df_train,df_test):\n",
    "    clf_RFC = RandomForestClassifier()\n",
    "    start_time = time.time()\n",
    "    df_train = stopwords_removal(df_train)\n",
    "    df_test_gold = stopwords_removal(df_test)\n",
    "    feature,feature_test = vectorizer_tfidf(df_train,df_test_gold)\n",
    "    clf_RFC.fit(feature,df_train['language'])\n",
    "    predictions = clf_RFC.predict(feature_test)\n",
    "    print(classification_report(df_test_gold['language'],predictions))\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time-start_time\n",
    "    print(\"Time taken to run Random Forest Classifier is %f seconds\" %time_taken)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Classification Report and Time to Run AdaBoost Classifier\n",
    "\n",
    "@param: df_train: Training dataFrame \n",
    "@param: df_test_gold: Testing dataFrame with gold standard\n",
    "\n",
    "@return: void \n",
    "\n",
    "'''\n",
    "def fit_predict_Ada(df_train,df_test):\n",
    "    clf_ada = AdaBoostClassifier()\n",
    "    start_time = time.time()\n",
    "    df_train = stopwords_removal(df_train)\n",
    "    df_test_gold = stopwords_removal(df_test)\n",
    "    feature,feature_test = vectorizer_tfidf(df_train,df_test_gold)\n",
    "    clf_ada.fit(feature,df_train['language'])\n",
    "    predictions = clf_ada.predict(feature_test)\n",
    "    print(classification_report(df_test_gold['language'],predictions))\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    print(\"Time taken to run Ada Boost Classifier is %f seconds\" %time_taken)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Classification Report and Time to Run ExtraTreesClassifier\n",
    "\n",
    "@param: df_train: Training dataFrame \n",
    "@param: df_test_gold: Testing dataFrame with gold standard\n",
    "\n",
    "@return: void \n",
    "\n",
    "'''\n",
    "def fit_predict_Extra(df_train,df_test):\n",
    "    clf_extra = ExtraTreesClassifier()\n",
    "    start_time = time.time()\n",
    "    df_train = stopwords_removal(df_train)\n",
    "    df_test_gold = stopwords_removal(df_test)\n",
    "    feature,feature_test = vectorizer_tfidf(df_train,df_test_gold)\n",
    "    clf_extra.fit(feature,df_train['language'])\n",
    "    predictions = clf_extra.predict(feature_test)\n",
    "    print(classification_report(df_test_gold['language'],predictions))\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    print(\"Time taken to run Extra Trees Classifier is %f seconds\" %time_taken)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Classification Report and Time to Run SGDClassifier\n",
    "\n",
    "@param: df_train: Training dataFrame \n",
    "@param: df_test_gold: Testing dataFrame with gold standard\n",
    "\n",
    "@return: void \n",
    "\n",
    "'''\n",
    "def fit_predict_SGDC(df_train,df_test):\n",
    "    clf_sgdc = SGDClassifier()\n",
    "    start_time = time.time()\n",
    "    df_train = stopwords_removal(df_train)\n",
    "    df_test_gold = stopwords_removal(df_test)\n",
    "    feature,feature_test = vectorizer_tfidf(df_train,df_test_gold)\n",
    "    clf_sgdc.fit(feature,df_train['language'])\n",
    "    predictions = clf_sgdc.predict(feature_test)\n",
    "    print(classification_report(df_test_gold['language'],predictions))\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    print(\"Time taken to run Stochastic Gradient Descent Classifier is %f seconds\" %time_taken)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = preprocess(train_path)\n",
    "df_test = preprocess(test_path)\n",
    "fit_predict_SVC(df_train,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_predict_KNN(df_train,df_test)\n",
    "fit_predict_DTC(df_train,df_test)\n",
    "fit_predict_RFC(df_train,df_test)\n",
    "fit_predict_Ada(df_train,df_test)\n",
    "fit_predict_Extra(df_train,df_test)\n",
    "fit_predict_SGDC(df_train,df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
