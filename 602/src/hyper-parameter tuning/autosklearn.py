# -*- coding: utf-8 -*-
"""AutoSklearn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_xRxaQhvTbcrUrBEugmt-Zsd3mY1tr4S
"""

!pip install auto-sklearn

def load(path):
        data = []
        #Reading contents from file 
        file_contents = open(path,"r",encoding="utf-8")
        #Appending read data to the file
        data.append(file_contents.read())
        text = []
        language = []
        #splitting each instance by \n
        temp = data[0].split("\n")
        for i in range(len(temp)):
            #putting each instance's text into one column
            text.append(temp[i].split("\t")[0])
            #putting language variety into second column
            language.append(temp[i].split("\t")[1])
        #making the DataFrame    
        df = pd.DataFrame(data={'text':text,'language':language})
        return df

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd drive

ls

cd MyDrive/

ls

train_path = 'DSLCCv4.0_1/DSL-TRAIN.txt'
dev_path = 'DSLCCv4.0_1/DSL-DEV.txt'
test_path = 'DSLCCv4.0_1/DSL-TEST-GOLD.txt'

pwd

import pandas as pd

df_train = load(train_path)
df_test = load(test_path)
df_dev = load(dev_path)

df_train.columns

X_train = df_train['text']
y_train = df_train['language']

!pip install scipy==1.7.2

import scipy
print(scipy.__version__)

def special_character_removal1(df):
    #Removal of special characters : cleaning of data.
    spec_chars = ["!", '"', "#", "%", "&", "'", "(", ")",
    "*", "+", ",", "-", ".", "/", ":", ";", "<",
    "=", ">", "?", "@", "[", "\\", "]", "^", "_",
    "`", "{", "|", "}", "~", "â€“"]
    for char in spec_chars:
        df['text'] = df['text'].str.replace(char, ' ')
        df['text'] = df['text'].str.replace('https?://\S+|www\.\S+', ' ')
    return df

df_train = special_character_removal1(df_train)
df_test = special_character_removal1(df_test)

def vectorizer_tfidf(df_train,df_test_gold):
    vectorizer = TfidfVectorizer() 
    vectorizer.fit(df_train['text'])
    feature = vectorizer.transform(df_train['text'])
    feature_test = vectorizer.transform(df_test_gold['text'])
    return feature,feature_test

df_train = df_train[df_train['language'].isin(['pt-BR','pt-PT'])]
df_test = df_test[df_test['language'].isin(['pt-BR','pt-PT'])]

from sklearn.feature_extraction.text import TfidfVectorizer

feature,feature_test = vectorizer_tfidf(df_train,df_test)

feature

feature_test

y_train = df_train['language']
y_test = df_test['language']

y_train

from pynvml import *
   
try:
    nvmlInit()
    print("Initalized correctly globally")
except:
    print("Failure to initalize globally")

import autosklearn.classification
cls = autosklearn.classification.AutoSklearnClassifier(
  n_jobs=-1)
cls.fit(feature, y_train)
cls.cv_results_

predictions = cls.predict(feature_test)

cls

from sklearn.metrics import classification_report

print(classification_report(y_test,predictions))